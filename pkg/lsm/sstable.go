package lsm

import (
	"bytes"
	"encoding/binary"
	"errors"
	"os"
)

// --- On-disk basics ---

const (
	// sstMagic is a placeholder magic number for SSTable files.
	sstMagic   uint64 = 0x626c6b537354626c
	sstVersion uint32 = 1
)

// BlockHandle represents a [offset, length] region in the SSTable file.
type BlockHandle struct {
	Offset uint64
	Length uint64
}

// Footer is placed at the end of the file and references the index and filter blocks.
type Footer struct {
	IndexHandle  BlockHandle
	FilterHandle BlockHandle
	Version      uint32
	Magic        uint64
}

// --- Compression interfaces (stubs) ---

// Compressor defines an interface for optional block compression.
type Compressor interface {
	Name() string
	Compress(in []byte) ([]byte, error)
	Decompress(in []byte) ([]byte, error)
}

// noCompression is a stub that performs no compression.
type noCompression struct{}

func (n *noCompression) Name() string { return "none" }

func (n *noCompression) Compress(in []byte) ([]byte, error) { return in, nil }

func (n *noCompression) Decompress(in []byte) ([]byte, error) { return in, nil }

// --- Filter policy interfaces (Bloom stub) ---

// FilterPolicy provides a per-table filter (e.g., Bloom) to avoid unnecessary IO.
type FilterPolicy interface {
	Name() string
	MayContain(key []byte, filter []byte) bool
	Build(keys [][]byte) []byte
}

// BloomPolicy is a stub implementation with configurable false positive rate.
type BloomPolicy struct{ FpRate float64 }

func (b *BloomPolicy) Name() string { return "bloom" }

func (b *BloomPolicy) MayContain(_ []byte, _ []byte) bool { return true }

func (b *BloomPolicy) Build(_ [][]byte) []byte { return nil }

// --- Block builders/readers (skeleton) ---

// blockBuilder accumulates KV pairs into a data block using prefix/delta encoding
/*
Cursor generated blockBuilder code
Implemented full LevelDB-style blockBuilder:
Add now encodes entries as varints [shared][unshared][valLen] then appends unshared key and value.
Starts a restart at every 16th entry and records its block offset.
Finish appends restart offsets and the count (little-endian uint32).
Added commonPrefixLen helper.
This seals blocks with restart metadata and prefix-compressed keys, ready for compression and writing.
*/
type blockBuilder struct {
	buf      []byte
	restarts []uint32
	counter  int
	lastKey  []byte
}

func (b *blockBuilder) Reset() {
	b.buf = b.buf[:0]
	b.restarts = b.restarts[:0]
	b.counter = 0
	b.lastKey = nil
}

// Add appends an entry encoded as [shared][unshared][valLen][unsharedKey][value].
// shared/unshared/valLen are varints. Every 16 entries we start a new restart (shared=0).
// Generated by Cursor
func (b *blockBuilder) Add(key []byte, value []byte) {
	const restartInterval = 16
	var shared int
	if b.counter%restartInterval == 0 {
		// Start of a restart point: remember block offset; no prefix sharing
		b.restarts = append(b.restarts, uint32(len(b.buf)))
		shared = 0
	} else {
		shared = commonPrefixLen(b.lastKey, key)
	}
	unshared := len(key) - shared

	var hdr [10]byte
	n := binary.PutUvarint(hdr[:], uint64(shared))
	b.buf = append(b.buf, hdr[:n]...)
	n = binary.PutUvarint(hdr[:], uint64(unshared))
	b.buf = append(b.buf, hdr[:n]...)
	n = binary.PutUvarint(hdr[:], uint64(len(value)))
	b.buf = append(b.buf, hdr[:n]...)
	b.buf = append(b.buf, key[shared:]...)
	b.buf = append(b.buf, value...)

	b.counter++
	b.lastKey = append(b.lastKey[:0], key...)
}

// Generated by Cursor
func (b *blockBuilder) Finish() []byte {
	// Ensure at least one restart (offset 0) so readers have a baseline.
	if len(b.restarts) == 0 {
		b.restarts = append(b.restarts, 0)
	}
	// Append restart offsets (uint32 little-endian) followed by restart count.
	for _, r := range b.restarts {
		var tmp [4]byte
		binary.LittleEndian.PutUint32(tmp[:], r)
		b.buf = append(b.buf, tmp[:]...)
	}
	var cnt [4]byte
	binary.LittleEndian.PutUint32(cnt[:], uint32(len(b.restarts)))
	b.buf = append(b.buf, cnt[:]...)
	return b.buf
}

// commonPrefixLen returns the length of the common prefix of a and b.
func commonPrefixLen(a, b []byte) int {
	n := len(a)
	if len(b) < n {
		n = len(b)
	}
	i := 0
	for i < n && a[i] == b[i] {
		i++
	}
	return i
}

// blockReader reads a single data block (stubbed).
type blockReader struct{}

// make sure blockReader is referenced to avoid unused warnings in skeleton stage
var _ = blockReader{}

func (br blockReader) Get(_ []byte) (val []byte, ok bool) { return nil, false }

// blockIter iterates entries within a single block (stubbed).
type blockIter struct{}

// --- Index and filter builders (skeleton) ---

type indexEntry struct {
	SepKey []byte
	Hdl    BlockHandle
}

type indexBuilder struct{ entries []indexEntry }

func (ib *indexBuilder) Add(sepKey []byte, h BlockHandle) {
	ib.entries = append(ib.entries, indexEntry{SepKey: append([]byte(nil), sepKey...), Hdl: h})
}

func (ib *indexBuilder) Finish() []byte {
	// trivial encoding: [kLen][k][offset(8)][length(8)] per entry
	var buf []byte
	var hdr [10]byte
	for _, e := range ib.entries {
		n := binary.PutUvarint(hdr[:], uint64(len(e.SepKey)))
		buf = append(buf, hdr[:n]...)
		buf = append(buf, e.SepKey...)
		tmp := make([]byte, 8)
		binary.LittleEndian.PutUint64(tmp, e.Hdl.Offset)
		buf = append(buf, tmp...)
		binary.LittleEndian.PutUint64(tmp, e.Hdl.Length)
		buf = append(buf, tmp...)
	}
	return buf
}

// filterBuilder accumulates keys per data-block for filter construction (stubbed).
type filterBuilder struct {
	policy FilterPolicy
	buf    []byte
}

func (fb *filterBuilder) StartBlock(blockOffset uint64) {
	// append block boundary marker
	tmp := make([]byte, 8)
	binary.LittleEndian.PutUint64(tmp, blockOffset)
	fb.buf = append(fb.buf, tmp...)
}

func (fb *filterBuilder) AddKey(userKey []byte) {
	var hdr [10]byte
	n := binary.PutUvarint(hdr[:], uint64(len(userKey)))
	fb.buf = append(fb.buf, hdr[:n]...)
	fb.buf = append(fb.buf, userKey...)
}

func (fb *filterBuilder) Finish() []byte { return fb.buf }

// --- Table writer (skeleton) ---

type tableWriter struct {
	// destination (e.g., *os.File) will be added in a later step
	f           *os.File
	opts        Options
	cmp         func(a, b []byte) int
	blockSize   int
	compressor  Compressor
	filter      *filterBuilder
	dataBuilder *blockBuilder
	index       *indexBuilder

	// rolling state
	pendingFirstKey []byte
	offset          uint64

	// ordering check, for global state
	lastUserKey []byte
	lastSeq     uint64
	seenAny     bool

	// size estimate for current block
	curBlockApprox int
}

// Add expects InternalKey ordered by userKey asc and seq desc.
// 会被db调用 按照immutable memtable的顺序写入ss table, 所以ikey是有序的
func (tw *tableWriter) Add(ikey InternalKey, value []byte) error {
	if tw.seenAny {
		c := bytes.Compare(ikey.UserKey, tw.lastUserKey)
		if c < 0 {
			return errors.New("tableWriter.Add: out-of-order userKey")
		}
		if c == 0 && ikey.Seq > tw.lastSeq {
			return errors.New("tableWriter.Add: out-of-order seq for same userKey")
		}
	} else {
		tw.seenAny = true
	}
	tw.lastUserKey = append(tw.lastUserKey[:0], ikey.UserKey...)
	tw.lastSeq = ikey.Seq

	// if it is the start of the new block
	if tw.curBlockApprox == 0 && len(tw.pendingFirstKey) == 0 {
		tw.pendingFirstKey = append(tw.pendingFirstKey[:0], ikey.UserKey...)
		// indicate start of a new data block to filter (boundary will be finalized on flush)
	}
	// Write to current block
	tw.dataBuilder.Add(ikey.UserKey, value)
	tw.curBlockApprox += len(ikey.UserKey) + len(value) + 8
	// TODO: Add Bloom Filter
	if tw.filter != nil {
		tw.filter.AddKey(ikey.UserKey)
	}

	if tw.curBlockApprox >= tw.blockSize {
		if err := tw.flushCurrentBlock(); err != nil {
			return err
		}
	}
	return nil
}

// TODO: implement this
func (tw *tableWriter) Finish() (Footer, error) {
	// flush last partial block
	if tw.curBlockApprox > 0 {
		if err := tw.flushCurrentBlock(); err != nil {
			return Footer{}, err
		}
	}

	return Footer{}, nil
}

func (tw *tableWriter) Close() error { return nil }

// flushCurrentBlock finalizes and writes the current data block
func (tw *tableWriter) flushCurrentBlock() error {
	raw := tw.dataBuilder.Finish()
	out, err := tw.compressor.Compress(raw)
	if err != nil {
		return err
	}
	// TODO: Add Bloom Filter
	if tw.filter != nil {
		tw.filter.StartBlock(tw.offset)
	}
	if err := writeAtAll(tw.f, int64(tw.offset), out); err != nil {
		return err
	}
	h := BlockHandle{Offset: tw.offset, Length: uint64(len(out))}
	if tw.index != nil && len(tw.pendingFirstKey) > 0 {
		tw.index.Add(tw.pendingFirstKey, h)
	}
	tw.offset += uint64(len(out))
	tw.dataBuilder.Reset()
	// reset to empty state for the next block
	tw.pendingFirstKey = tw.pendingFirstKey[:0]
	tw.curBlockApprox = 0

	// don't need to reset these because they maintain global state for ALL blocks in SST
	// tw.seenAny = false
	// tw.lastUserKey = tw.lastUserKey[:0]
	// tw.lastSeq = 0
	return nil
}

// NewTableWriter constructs a new file-backed table writer.
func NewTableWriter(f *os.File, opts Options) (*tableWriter, error) {
	if f == nil {
		return nil, errors.New("nil file")
	}
	blkSize := opts.BlockSize
	if blkSize <= 0 {
		blkSize = 4 << 10 // 4 * 2^10 = 4KB. 2^10 is 1KB
	}
	tw := &tableWriter{
		f:           f,
		opts:        opts,
		cmp:         bytes.Compare,
		blockSize:   blkSize,
		compressor:  pickCompressor(opts.Compression),                        // No compression for now
		filter:      &filterBuilder{policy: defaultFilter(opts.BloomFpRate)}, // Ignore. TODO: Add Bloom Filter
		dataBuilder: &blockBuilder{},
		index:       &indexBuilder{},
	}
	return tw, nil
}

// helpers
func writeAtAll(f *os.File, offset int64, p []byte) error {
	bytesToWrite := len(p)
	for bytesToWrite > 0 {
		n, err := f.WriteAt(p, offset)
		if err != nil {
			return err
		}
		bytesToWrite -= n
		offset += int64(n)
		p = p[n:]
	}
	return nil
}

// Generated by Cursor
func encodeFooter(f Footer) []byte {
	buf := make([]byte, 0, 44)
	put64 := func(x uint64) {
		tmp := make([]byte, 8)
		binary.LittleEndian.PutUint64(tmp, x)
		buf = append(buf, tmp...)
	}
	put32 := func(x uint32) {
		tmp := make([]byte, 4)
		binary.LittleEndian.PutUint32(tmp, x)
		buf = append(buf, tmp...)
	}
	put64(f.IndexHandle.Offset)
	put64(f.IndexHandle.Length)
	put64(f.FilterHandle.Offset)
	put64(f.FilterHandle.Length)
	put32(f.Version)
	put64(f.Magic)
	return buf
}

// --- Table reader (skeleton) ---

type tableReader struct {
	// source (e.g., *os.File) will be added in a later step
	opts       Options
	compressor Compressor
	filter     FilterPolicy
	indexData  []byte
	footer     Footer
}

func OpenTable(_ string, opts Options) (*tableReader, error) {
	tr := &tableReader{
		opts:       opts,
		compressor: pickCompressor(opts.Compression),
		filter:     defaultFilter(opts.BloomFpRate),
	}
	return tr, nil
}

func (tr *tableReader) Get(_ []byte, _ uint64) ([]byte, bool, error) { return nil, false, nil }

func (tr *tableReader) NewIterator(_ *ReadOptions) Iterator { return nil }

func (tr *tableReader) Close() error {
	// reference fields to avoid unused field warnings in skeleton stage
	_ = tr.indexData
	_ = tr.footer
	return nil
}

// --- Option wiring helpers ---

func pickCompressor(_ string) Compressor { return &noCompression{} }

func defaultFilter(fpRate float64) FilterPolicy { return &BloomPolicy{FpRate: fpRate} }
